#!/usr/bin/env python3
"""
Quick test for F5-TTS-THAI model inference
"""

import os
import sys
import tempfile

def test_model_inference():
    """Test direct model inference"""
    print("üß™ Testing F5-TTS-THAI Model Inference")
    print("=" * 50)
    
    # Check for model
    model_paths = ["model_1000000.pt", "models/model_1000000.pt"]
    model_path = None
    for path in model_paths:
        if os.path.exists(path):
            model_path = path
            break
    
    if not model_path:
        print("‚ùå Model not found")
        return False
    
    print(f"‚úÖ Model found: {model_path}")
    
    try:
        # Import F5-TTS components
        import torch
        from f5_tts.model import DiT
        from f5_tts.infer.utils_infer import load_model, infer_process
        
        print("‚úÖ F5-TTS imports successful")
        
        # Check for VIZINTZOR vocab file
        vocab_paths = [
            "vocab.txt", 
            "models/vocab.txt", 
            "F5-TTS-THAI/vocab.txt"
        ]
        
        vocab_file = None
        for vpath in vocab_paths:
            if os.path.exists(vpath):
                vocab_file = vpath
                print(f"‚úÖ Found vocab file: {vocab_file}")
                break
        
        if not vocab_file:
            print("üìÅ Downloading VIZINTZOR vocab file...")
            try:
                # Try to download the correct vocab file from VIZINTZOR
                try:
                    from huggingface_hub import hf_hub_download
                    vocab_file = hf_hub_download(
                        repo_id="VIZINTZOR/F5-TTS-THAI",
                        filename="vocab.txt",
                        local_dir="./models"
                    )
                except ImportError:
                    try:
                        from huggingface_hub import cached_path
                        vocab_file = str(cached_path("hf://VIZINTZOR/F5-TTS-THAI/vocab.txt"))
                    except ImportError:
                        print("‚ùå HuggingFace Hub not available")
                        vocab_file = None
                
                if vocab_file:
                    print(f"‚úÖ Downloaded vocab: {vocab_file}")
                else:
                    print("‚ùå Could not download vocab file")
                    
            except Exception as e:
                print(f"‚ùå Vocab download failed: {e}")
                vocab_file = None
        
        # Load model with correct vocab
        F5TTS_model_cfg = dict(
            dim=1024, depth=22, heads=16, ff_mult=2, 
            text_dim=512, conv_layers=4
        )
        
        print("üîÑ Loading model with VIZINTZOR vocabulary...")
        print(f"üìã Model path: {model_path}")
        print(f"üìã Vocab file: {vocab_file}")
        
        model = load_model(DiT, F5TTS_model_cfg, model_path, vocab_file=vocab_file, use_ema=True)
        print(f"‚úÖ Model loaded: {type(model)}")
        
        # Check model attributes
        print(f"üìã Model attributes: {[attr for attr in dir(model) if not attr.startswith('_')]}")
        
        # Try to load vocoder
        try:
            from f5_tts.infer.utils_infer import load_vocoder
            vocoder = load_vocoder()
            print(f"‚úÖ Vocoder loaded: {type(vocoder)}")
        except Exception as e:
            print(f"‚ö†Ô∏è Vocoder loading failed: {e}")
            vocoder = None
        
        # Test inference
        print("üîÑ Testing inference...")
        
        test_text = "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö"
        ref_text = "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"
        
        # Create a simple reference audio using gTTS
        ref_audio_path = None
        try:
            from gtts import gTTS
            temp_ref = tempfile.NamedTemporaryFile(suffix='.mp3', delete=False)
            tts = gTTS(text=ref_text, lang='th')
            tts.save(temp_ref.name)
            ref_audio_path = temp_ref.name
            print(f"‚úÖ Reference audio created: {ref_audio_path}")
        except Exception as e:
            print(f"‚ö†Ô∏è Reference audio creation failed: {e}")
        
        # Test inference
        try:
            final_wave, final_sample_rate, _ = infer_process(
                ref_audio=ref_audio_path,
                ref_text=ref_text,
                gen_text=test_text,
                model_obj=model,  # Fixed: parameter name is model_obj, not model
                vocoder=vocoder,
                nfe_step=16,  # Faster for testing
                speed=1.0,
                cfg_strength=2.0
            )
            
            print(f"‚úÖ Inference successful!")
            print(f"üìä Audio shape: {final_wave.shape if hasattr(final_wave, 'shape') else type(final_wave)}")
            print(f"üìä Sample rate: {final_sample_rate}")
            
            # Save test output
            import soundfile as sf
            output_path = "test_inference_output.wav"
            
            # Convert to numpy if needed
            if hasattr(final_wave, 'cpu'):
                audio_array = final_wave.cpu().numpy()
            elif hasattr(final_wave, 'numpy'):
                audio_array = final_wave.numpy()
            else:
                audio_array = final_wave
            
            sf.write(output_path, audio_array, final_sample_rate)
            print(f"‚úÖ Test output saved: {output_path}")
            
            # Clean up
            if ref_audio_path and os.path.exists(ref_audio_path):
                os.unlink(ref_audio_path)
            
            return True
            
        except Exception as e:
            print(f"‚ùå Inference failed: {e}")
            import traceback
            print(f"üîç Full error: {traceback.format_exc()}")
            return False
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        import traceback
        print(f"üîç Full error: {traceback.format_exc()}")
        return False

if __name__ == "__main__":
    if test_model_inference():
        print("\nüéâ Model inference test passed!")
    else:
        print("\n‚ùå Model inference test failed!")
