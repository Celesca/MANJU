<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fixed Thai ASR - No More Concatenation!</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
            font-weight: bold;
        }
        .status.connected { background: #d4edda; color: #155724; }
        .status.recording { background: #fff3cd; color: #856404; }
        .status.error { background: #f8d7da; color: #721c24; }
        
        .transcription-box {
            border: 2px solid #ddd;
            border-radius: 8px;
            padding: 15px;
            margin: 15px 0;
            min-height: 100px;
            background: #f9f9f9;
        }
        .realtime { border-color: #007bff; background: #e7f3ff; }
        .final { border-color: #28a745; background: #e8f5e9; }
        
        button {
            padding: 12px 24px;
            margin: 5px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
            font-weight: bold;
        }
        .start-btn { background: #28a745; color: white; }
        .stop-btn { background: #dc3545; color: white; }
        .clear-btn { background: #6c757d; color: white; }
        
        .features {
            background: #e7f3ff;
            padding: 15px;
            border-radius: 8px;
            margin: 20px 0;
        }
        .features h3 { margin-top: 0; color: #0056b3; }
        .features ul { margin: 0; }
        .features li { margin: 5px 0; }
        
        .stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 10px;
            margin: 20px 0;
        }
        .stat-box {
            background: #f8f9fa;
            padding: 10px;
            border-radius: 5px;
            text-align: center;
        }
        .stat-value { font-size: 18px; font-weight: bold; color: #007bff; }
        .stat-label { font-size: 12px; color: #666; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Fixed Thai ASR Server</h1>
        <p><strong>No More Concatenation Issues!</strong></p>
        
        <div class="features">
            <h3>‚ú® New Features:</h3>
            <ul>
                <li>‚úÖ Chunked transcription - no more text repetition!</li>
                <li>‚úÖ Auto-stop when speech ends</li>
                <li>‚úÖ Fast real-time updates without concatenation</li>
                <li>‚úÖ Clean, fresh transcription for each utterance</li>
                <li>‚úÖ Parallel processing with async/await</li>
            </ul>
        </div>
        
        <div id="status" class="status">Connecting to server...</div>
        
        <div>
            <button id="startBtn" class="start-btn" onclick="startRecording()">üé§ Start Recording</button>
            <button id="stopBtn" class="stop-btn" onclick="stopRecording()" disabled>‚èπÔ∏è Stop Recording</button>
            <button class="clear-btn" onclick="clearTranscriptions()">üóëÔ∏è Clear</button>
        </div>
        
        <div class="stats" id="stats" style="display: none;">
            <div class="stat-box">
                <div class="stat-value" id="chunkCount">0</div>
                <div class="stat-label">Audio Chunks</div>
            </div>
            <div class="stat-box">
                <div class="stat-value" id="utteranceCount">0</div>
                <div class="stat-label">Utterances</div>
            </div>
            <div class="stat-box">
                <div class="stat-value" id="speechActive">No</div>
                <div class="stat-label">Speech Active</div>
            </div>
        </div>
        
        <h3>Real-time Transcription (Live Updates):</h3>
        <div id="realtimeBox" class="transcription-box realtime">
            Real-time text will appear here as you speak...
        </div>
        
        <h3>Final Transcription (Complete Utterances):</h3>
        <div id="finalBox" class="transcription-box final">
            Final transcriptions will appear here when you stop speaking...
        </div>
    </div>

    <script>
        let audioWS = null;
        let controlWS = null;
        let mediaRecorder = null;
        let audioContext = null;
        let chunkCount = 0;
        let utteranceCount = 0;
        
        // WebSocket URLs - update if using ngrok
        const CONTROL_URL = 'ws://localhost:8765';
        const AUDIO_URL = 'ws://localhost:8766';
        
        // Connect to WebSocket servers
        function connectWebSockets() {
            // Control WebSocket
            controlWS = new WebSocket(CONTROL_URL);
            controlWS.onopen = () => {
                console.log('Control WebSocket connected');
            };
            controlWS.onmessage = (event) => {
                const data = JSON.parse(event.data);
                console.log('Control message:', data);
            };
            
            // Audio WebSocket
            audioWS = new WebSocket(AUDIO_URL);
            audioWS.onopen = () => {
                updateStatus('Connected to server! Ready to record.', 'connected');
                document.getElementById('stats').style.display = 'grid';
            };
            audioWS.onmessage = (event) => {
                const data = JSON.parse(event.data);
                handleAudioMessage(data);
            };
            audioWS.onerror = () => {
                updateStatus('Connection failed! Make sure server is running.', 'error');
            };
        }
        
        function handleAudioMessage(data) {
            switch(data.type) {
                case 'realtime_transcription':
                    document.getElementById('realtimeBox').innerHTML = 
                        `<strong>üîÑ Live:</strong> ${data.text}<br><small>‚è±Ô∏è ${new Date(data.timestamp).toLocaleTimeString()}</small>`;
                    break;
                    
                case 'final_transcription':
                    const finalBox = document.getElementById('finalBox');
                    utteranceCount++;
                    finalBox.innerHTML += 
                        `<div style="margin: 10px 0; padding: 10px; background: white; border-radius: 5px;">
                            <strong>‚úÖ Final:</strong> ${data.text}<br>
                            <small>‚è±Ô∏è ${new Date(data.timestamp).toLocaleTimeString()} | 
                            üïê ${data.processing_time?.toFixed(2)}s | 
                            üìè ${data.duration?.toFixed(1)}s audio</small>
                        </div>`;
                    finalBox.scrollTop = finalBox.scrollHeight;
                    updateStats();
                    break;
                    
                case 'recording_auto_stopped':
                    updateStatus('Recording auto-stopped (speech ended)', 'connected');
                    document.getElementById('startBtn').disabled = false;
                    document.getElementById('stopBtn').disabled = true;
                    break;
                    
                case 'error':
                    updateStatus(`Error: ${data.message}`, 'error');
                    break;
            }
        }
        
        function updateStatus(message, type) {
            const statusEl = document.getElementById('status');
            statusEl.textContent = message;
            statusEl.className = `status ${type}`;
        }
        
        function updateStats() {
            document.getElementById('chunkCount').textContent = chunkCount;
            document.getElementById('utteranceCount').textContent = utteranceCount;
        }
        
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    } 
                });
                
                // Send start recording message
                if (controlWS && controlWS.readyState === WebSocket.OPEN) {
                    controlWS.send(JSON.stringify({ type: 'start_recording' }));
                }
                
                // Set up MediaRecorder
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0 && audioWS && audioWS.readyState === WebSocket.OPEN) {
                        // Convert to base64 and send
                        const reader = new FileReader();
                        reader.onload = () => {
                            const base64 = reader.result.split(',')[1];
                            audioWS.send(JSON.stringify({
                                type: 'audio_chunk',
                                data: base64
                            }));
                            chunkCount++;
                            updateStats();
                        };
                        reader.readAsDataURL(event.data);
                    }
                };
                
                mediaRecorder.start(100); // Send chunks every 100ms
                
                updateStatus('üé§ Recording... Speak now!', 'recording');
                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                
            } catch (error) {
                updateStatus('Microphone access denied!', 'error');
                console.error('Error starting recording:', error);
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
            }
            
            if (controlWS && controlWS.readyState === WebSocket.OPEN) {
                controlWS.send(JSON.stringify({ type: 'stop_recording' }));
            }
            
            if (audioWS && audioWS.readyState === WebSocket.OPEN) {
                audioWS.send(JSON.stringify({ type: 'audio_end' }));
            }
            
            updateStatus('Recording stopped', 'connected');
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
        }
        
        function clearTranscriptions() {
            document.getElementById('realtimeBox').innerHTML = 'Real-time text will appear here as you speak...';
            document.getElementById('finalBox').innerHTML = 'Final transcriptions will appear here when you stop speaking...';
            chunkCount = 0;
            utteranceCount = 0;
            updateStats();
        }
        
        // Initialize on page load
        window.onload = () => {
            connectWebSockets();
        };
        
        // Clean up on page unload
        window.onbeforeunload = () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                stopRecording();
            }
        };
    </script>
</body>
</html>
